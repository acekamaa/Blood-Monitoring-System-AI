#dummy_data.py
# Contains random data to be used in this project and is basically for testing and training the models.
# This data is to be replaced with the real data once deployed for use.

#blood_type_dummy_data.csv
# The randomly generated data is stored in this file.
# The file undergoes cleaning and preprocessing later.

#load_process_data.py
# The models and label encoder are saved to a specified directory for later use, ensuring that the trained models can be reused without retraining.
# The preprocessed data is saved in CSV format, making it easy to load and use in other applications or analyses.
# The code is designed to be run in a Python environment with the necessary libraries installed, and it assumes that the dummy data CSV file is located in the specified path.
# The code is intended to be run as a standalone script, but it can also be integrated into larger applications or workflows as needed.
# The classifiers are chosen based on their popularity and effectiveness in classification tasks, providing a good balance between complexity and performance.  
# The code can be further extended to include hyperparameter tuning, cross-validation, and other advanced techniques to improve model performance if desired.
# The classifiers are trained on the preprocessed data, and their performance is evaluated using accuracy and classification reports.